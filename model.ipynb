{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "import numpy as np\n",
    "import glob \n",
    "graph = Graph()\n",
    "for filename in glob.glob('reduced_kgs/reduced_*'):\n",
    "    graph.load(filename,format=filename.split('.')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218327"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58176, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = set(graph.subjects()) | set(graph.objects())\n",
    "relations = set(graph.predicates())\n",
    "len(entities), len(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mappings = {e:i for i,e in enumerate(entities)}\n",
    "relation_mappings = {e:i for i,e in enumerate(relations)}\n",
    "triples = np.asarray(list(map(lambda x: (entity_mappings[x[0]],\n",
    "                                         relation_mappings[x[1]],\n",
    "                                         entity_mappings[x[2]]),graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "def TransE(dim=200,bias=1,lamb=1):\n",
    "    \n",
    "    inp = Input((3,))\n",
    "    inp_label = Input(())\n",
    "    \n",
    "    s,p,o = tf.unstack(inp,axis=-1)\n",
    "    \n",
    "    entity_embedding = Embedding(len(entities),dim,name='entity_embedding')\n",
    "    relation_embedding = Embedding(len(relations),dim,name='relation_embedding')\n",
    "    \n",
    "    h,r,t = entity_embedding(s),relation_embedding(p),entity_embedding(o)\n",
    "    \n",
    "    score = bias - tf.norm(h+r-t, ord=2, axis=-1)\n",
    "    \n",
    "    loss = lamb - inp_label * score\n",
    "    loss = tf.where(loss>0,loss,0) + \\\n",
    "    1e-3 * tf.norm(entity_embedding.weights[0],ord=2)**2\n",
    "    \n",
    "    model = Model(inputs=[inp,inp_label],outputs=score)\n",
    "    model.add_loss(loss)\n",
    "    model.compile(optimizer='adam',loss=None)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def DistMult(dim=200):\n",
    "    inp = Input((3,))\n",
    "    inp_label = Input(())\n",
    "    \n",
    "    s,p,o = tf.unstack(inp,axis=-1)\n",
    "    \n",
    "    entity_embedding = Embedding(len(entities),dim,name='entity_embedding')\n",
    "    relation_embedding = Embedding(len(relations),dim,name='relation_embedding')\n",
    "    \n",
    "    h,r,t = entity_embedding(s),relation_embedding(p),entity_embedding(o)\n",
    "    \n",
    "    score = tf.keras.layers.Activation('tanh')(tf.reduce_sum(h*r*t,axis=-1))\n",
    "    \n",
    "    model = Model(inputs=[inp,inp_label],outputs=score)\n",
    "    \n",
    "    loss = lambda true,pred: tf.reduce_sum(tf.math.log(1+tf.math.exp(-true*pred))) + \\\n",
    "    1e-3 * tf.norm(entity_embedding.weights[0],ord=2)**2\n",
    "    \n",
    "    model.compile(optimizer='adam',loss=loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def ComplEx(dim=200):\n",
    "    inp = Input((3,))\n",
    "    inp_label = Input(())\n",
    "    \n",
    "    s,p,o = tf.unstack(inp,axis=-1)\n",
    "    \n",
    "    entity_embedding = Embedding(len(entities),dim,name='entity_embedding')\n",
    "    relation_embedding = Embedding(len(relations),dim,name='relation_embedding')\n",
    "    \n",
    "    h,r,t = entity_embedding(s),relation_embedding(p),entity_embedding(o)\n",
    "    \n",
    "    h_real,h_img = tf.split(h,2,axis=-1)\n",
    "    r_real,r_img = tf.split(r,2,axis=-1)\n",
    "    t_real,t_img = tf.split(t,2,axis=-1)\n",
    "    \n",
    "    score = tf.reduce_sum(r_real*h_real*t_real,axis=-1) + \\\n",
    "    tf.reduce_sum(r_real*h_img*t_img,axis=-1) + \\\n",
    "    tf.reduce_sum(r_img*h_real*t_img,axis=-1) - \\\n",
    "    tf.reduce_sum(r_img*h_img*t_real,axis=-1)\n",
    "        \n",
    "    model = Model(inputs=[inp,inp_label],outputs=score)\n",
    "    \n",
    "    loss = lambda true,pred: tf.reduce_sum(tf.math.log(1+tf.math.exp(-true*pred))) + \\\n",
    "    1e-3 * tf.norm(entity_embedding.weights[0],ord=2)**2\n",
    "    \n",
    "    model.compile(optimizer='adam',loss=loss)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative(positive,n=2):\n",
    "    negative = np.repeat(positive,n,axis=0)\n",
    "    negative[:,0] = np.random.randint(0,len(entities),size=len(negative))\n",
    "    negative[:,2] = np.random.randint(0,len(entities),size=len(negative))\n",
    "    return negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.7 ms ± 824 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit create_negative(triples,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 28s 95ms/step - loss: 5679.1426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:28<46:47, 28.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 28s 95ms/step - loss: 3405.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:56<46:14, 28.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 28s 96ms/step - loss: 1198.2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [01:24<45:47, 28.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 29s 97ms/step - loss: 932.3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [01:53<45:29, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 29s 98ms/step - loss: 767.9037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [02:22<45:14, 28.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 29s 98ms/step - loss: 649.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [02:51<44:53, 28.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 29s 98ms/step - loss: 567.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [03:20<44:32, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 28s 95ms/step - loss: 508.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [03:48<43:47, 28.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 28s 95ms/step - loss: 466.8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [04:16<43:06, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 28s 94ms/step - loss: 433.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [04:44<42:23, 28.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/294 [========================>.....] - ETA: 4s - loss: 408.6066"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "embedding_model = ComplEx()\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience=10\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    \n",
    "    negative = create_negative(triples,n=10)\n",
    "    \n",
    "    X = np.concatenate([triples,negative],axis=0)\n",
    "    y = np.concatenate([np.ones(len(triples)),-1*np.ones(len(negative))],axis=0)\n",
    "    \n",
    "    hist = embedding_model.fit((X,y),y,\n",
    "                     batch_size=8192,\n",
    "                     shuffle=True,\n",
    "                     verbose=1)\n",
    "\n",
    "    l = hist.history['loss'][-1]\n",
    "    if l < best_loss:\n",
    "        best_loss = l\n",
    "        c = 0\n",
    "    else:\n",
    "        c += 1\n",
    "    \n",
    "    if c > patience: break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = embedding_model((X,y),training=False).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(p[:len(triples)]),np.mean(p[len(triples):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "effect_data = pd.read_csv('effect_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = {}\n",
    "\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from pubchempy import Compound\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = \"\"\"select ?cas ?pc where {\n",
    "  ?c wdt:P231 ?tmp ;\n",
    "     wdt:P662 ?pc .\n",
    "  bind(replace(?tmp,'-','') as ?cas)\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    chem_id = 'https://cfpub.epa.gov/ecotox/cas/'+result['cas']['value']\n",
    "    if chem_id in set(effect_data.chemical.values): \n",
    "        vioxx = Compound.from_cid(int(result['pc']['value']))\n",
    "        fps[chem_id] = vioxx.fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin(he): \n",
    "    scale = 16 ## equals to hexadecimal\n",
    "    num_of_bits = 900\n",
    "    return bin(int(he, scale))[2:].zfill(num_of_bits)\n",
    "\n",
    "effect_data['fp'] = [to_bin(fps[c]) if c in fps else to_bin('0') for c in effect_data['chemical'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_data = effect_data[effect_data['fp']!=to_bin('0')]\n",
    "effect_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = effect_data[['fp','species','chemical','conc (mol/L)']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray([[fp,\n",
    "                    entity_mappings[URIRef(s)],\n",
    "                    entity_mappings[URIRef(c)],\n",
    "                    conc] for fp,s,c,conc in data if URIRef(s) in entity_mappings and URIRef(c) in entity_mappings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.trainable=False\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "def mlp(input_shape,use_embedding=False):\n",
    "    \n",
    "    inp_s = Input(())\n",
    "    inp_c = Input(())\n",
    "    \n",
    "    if use_embedding:\n",
    "        s = embedding_model.get_layer('entity_embedding')(inp_s)\n",
    "        c = embedding_model.get_layer('entity_embedding')(inp_c)\n",
    "    else:\n",
    "        el = Embedding(len(entities),200)\n",
    "        s = el(inp_s)\n",
    "        c = el(inp_c)\n",
    "        \n",
    "    x = Concatenate(axis=-1)([s,c])\n",
    "    x = Dense(128,activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1)(x)\n",
    "    model = Model(inputs=[inp_s,inp_c],outputs=x)\n",
    "    model.compile(optimizer='adam',loss='mae')\n",
    "    return model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "Xs,Xc = data[:,1].astype(int),data[:,2].astype(int)\n",
    "y = data[:,3].astype('float32')\n",
    "X = data[:,0]\n",
    "\n",
    "X = np.asarray(list(map(lambda x: np.asarray([float(a) for a in x]), X))).astype('float32')\n",
    "\n",
    "oof = np.zeros(y.shape)\n",
    "oof_embedding = np.zeros(y.shape)\n",
    "\n",
    "for train,test in KFold(5).split(y):\n",
    "    model = mlp(X.shape[-1],use_embedding=False)\n",
    "    model.fit((Xs[train],Xc[train]),y[train],\n",
    "              validation_data=((Xs[test],Xc[test]),y[test]),\n",
    "              batch_size=8192,epochs=1000,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n",
    "    \n",
    "    oof[test] += model.predict((Xs[test],Xc[test])).ravel()\n",
    "    \n",
    "    model = mlp(X.shape[-1],use_embedding=True)\n",
    "    model.fit((Xs[train],Xc[train]),y[train],\n",
    "              validation_data=((Xs[test],Xc[test]),y[test]),\n",
    "              batch_size=8192,epochs=1000,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n",
    "    \n",
    "    oof_embedding[test] += model.predict((Xs[test],Xc[test])).ravel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y,oof),r2_score(y,oof_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "import numpy as np\n",
    "import glob \n",
    "graph = Graph()\n",
    "for filename in glob.glob('reduced_kgs/reduced_*'):\n",
    "    graph.load(filename,format=filename.split('.')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218327"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58176, 41)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = set(graph.subjects()) | set(graph.objects())\n",
    "relations = set(graph.predicates())\n",
    "len(entities), len(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mappings = {e:i for i,e in enumerate(entities)}\n",
    "relation_mappings = {e:i for i,e in enumerate(relations)}\n",
    "triples = np.asarray(list(map(lambda x: (entity_mappings[x[0]],\n",
    "                                         relation_mappings[x[1]],\n",
    "                                         entity_mappings[x[2]]),graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv2D, Flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "def TransE(dim=200,bias=1,lamb=1):\n",
    "    \n",
    "    inp = Input((3,))\n",
    "    inp_label = Input(())\n",
    "    \n",
    "    s,p,o = tf.unstack(inp,axis=-1)\n",
    "    \n",
    "    entity_embedding = Embedding(len(entities),dim,name='entity_embedding')\n",
    "    relation_embedding = Embedding(len(relations),dim,name='relation_embedding')\n",
    "    \n",
    "    h,r,t = entity_embedding(s),relation_embedding(p),entity_embedding(o)\n",
    "    \n",
    "    score = bias - tf.norm(h+r-t, ord=2, axis=-1)\n",
    "    \n",
    "    loss = lamb - inp_label * score\n",
    "    loss = tf.where(loss>0,loss,0) + \\\n",
    "    1e-3 * tf.norm(entity_embedding.weights[0],ord=2)**2\n",
    "    \n",
    "    model = Model(inputs=[inp,inp_label],outputs=score)\n",
    "    model.add_loss(loss)\n",
    "    model.compile(optimizer='adam',loss=None)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def DistMult(dim=200):\n",
    "    inp = Input((3,))\n",
    "    inp_label = Input(())\n",
    "    \n",
    "    s,p,o = tf.unstack(inp,axis=-1)\n",
    "    \n",
    "    entity_embedding = Embedding(len(entities),dim,name='entity_embedding')\n",
    "    relation_embedding = Embedding(len(relations),dim,name='relation_embedding')\n",
    "    \n",
    "    h,r,t = entity_embedding(s),relation_embedding(p),entity_embedding(o)\n",
    "    \n",
    "    score = tf.keras.layers.Activation('tanh')(tf.reduce_sum(h*r*t,axis=-1))\n",
    "    \n",
    "    model = Model(inputs=[inp,inp_label],outputs=score)\n",
    "    \n",
    "    loss = lambda true,pred: tf.reduce_sum(tf.math.log(1+tf.math.exp(-true*pred))) + \\\n",
    "    1e-3 * tf.norm(entity_embedding.weights[0],ord=2)**2\n",
    "    \n",
    "    model.compile(optimizer='adam',loss=loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def ComplEx(dim=200):\n",
    "    inp = Input((3,))\n",
    "    inp_label = Input(())\n",
    "    \n",
    "    s,p,o = tf.unstack(inp,axis=-1)\n",
    "    \n",
    "    entity_embedding = Embedding(len(entities),dim,name='entity_embedding')\n",
    "    relation_embedding = Embedding(len(relations),dim,name='relation_embedding')\n",
    "    \n",
    "    h,r,t = entity_embedding(s),relation_embedding(p),entity_embedding(o)\n",
    "    \n",
    "    h_real,h_img = tf.split(h,2,axis=-1)\n",
    "    r_real,r_img = tf.split(r,2,axis=-1)\n",
    "    t_real,t_img = tf.split(t,2,axis=-1)\n",
    "    \n",
    "    score = tf.reduce_sum(r_real*h_real*t_real,axis=-1) + \\\n",
    "    tf.reduce_sum(r_real*h_img*t_img,axis=-1) + \\\n",
    "    tf.reduce_sum(r_img*h_real*t_img,axis=-1) - \\\n",
    "    tf.reduce_sum(r_img*h_img*t_real,axis=-1)\n",
    "        \n",
    "    model = Model(inputs=[inp,inp_label],outputs=score)\n",
    "    \n",
    "    loss = lambda true,pred: tf.reduce_sum(tf.math.log(1+tf.math.exp(-true*pred))) + \\\n",
    "    1e-3 * tf.norm(entity_embedding.weights[0],ord=2)**2\n",
    "    \n",
    "    model.compile(optimizer='adam',loss=loss)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def ConvE():\n",
    "    inp = Input((3,))\n",
    "    inp_label = Input(())\n",
    "    \n",
    "    s,p,o = tf.unstack(inp,axis=-1)\n",
    "    \n",
    "    entity_embedding = Embedding(len(entities),200,name='entity_embedding')\n",
    "    relation_embedding = Embedding(len(relations),200,name='relation_embedding')\n",
    "    \n",
    "    h,r,t = entity_embedding(s),relation_embedding(p),entity_embedding(o)\n",
    "    \n",
    "    h = tf.reshape(h,(-1,20,10))\n",
    "    r = tf.reshape(r,(-1,20,10))\n",
    "    \n",
    "    x = Concatenate(axis=-1)([h,r])\n",
    "    \n",
    "    x = Conv2D(16,(5,5),activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(16,(3,3),activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(1,activation='sigmoid')\n",
    "    \n",
    "    model = Model(inputs=[inp,inp_label],outputs=x)\n",
    "    \n",
    "    loss = lambda true,pred: tf.keras.losses.binary_crossentropy(true,pred) + \\\n",
    "    1e-3 * tf.norm(entity_embedding.weights[0],ord=2)**2\n",
    "    \n",
    "    model.compile(optimizer='adam',loss=loss)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative(postive,n=2):\n",
    "    negative = np.repeat(postive,n,axis=0)\n",
    "    negative[:,0] = np.random.randint(0,len(entities),size=len(negative))\n",
    "    negative[:,2] = np.random.randint(0,len(entities),size=len(negative))\n",
    "    return negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.4 ms ± 450 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit create_negative(triples,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tqdm.notebook as tq\n",
    "\n",
    "embedding_model = ComplEx()\n",
    "\n",
    "best_loss = float('inf')\n",
    "losses = []\n",
    "patience=10\n",
    "\n",
    "if TRAINING:\n",
    "\n",
    "    for i in tq.tqdm(range(100)):\n",
    "\n",
    "        negative = create_negative(triples,n=32)\n",
    "\n",
    "        X = np.concatenate([triples,negative],axis=0)\n",
    "        y = np.concatenate([np.ones(len(triples)),-1*np.ones(len(negative))],axis=0)\n",
    "\n",
    "        hist = embedding_model.fit((X,y),y,\n",
    "                         batch_size=8192,\n",
    "                         shuffle=True,\n",
    "                         verbose=0)\n",
    "\n",
    "        l = hist.history['loss'][-1]\n",
    "        losses.append(l)\n",
    "        if l < best_loss:\n",
    "            best_loss = l\n",
    "            c = 0\n",
    "        else:\n",
    "            c += 1\n",
    "\n",
    "        if c > patience: break\n",
    "    \n",
    "    embedding_model.save_weights('model.tf')\n",
    "            \n",
    "else:\n",
    "    embedding_model.load_weights('model.tf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "if TRAINING:\n",
    "    plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "effect_data = pd.read_csv('effect_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = {}\n",
    "\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from pubchempy import Compound\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = \"\"\"select ?cas ?pc where {\n",
    "  ?c wdt:P231 ?tmp ;\n",
    "     wdt:P662 ?pc .\n",
    "  bind(replace(?tmp,'-','') as ?cas)\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "try: \n",
    "    fps = pd.read_pickle('fingerprints.pkl')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    \n",
    "    results = get_results(endpoint_url, query)\n",
    "    for result in tq.tqdm(results[\"results\"][\"bindings\"]):\n",
    "        chem_id = 'https://cfpub.epa.gov/ecotox/cas/'+result['cas']['value']\n",
    "        if chem_id in set(effect_data.chemical.values): \n",
    "            vioxx = Compound.from_cid(int(result['pc']['value']))\n",
    "            fps[chem_id] = vioxx.fingerprint\n",
    "    pd.to_pickle(fps,'fingerprints.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin(he): \n",
    "    scale = 16 ## equals to hexadecimal\n",
    "    num_of_bits = 900\n",
    "    return bin(int(he, scale))[2:].zfill(num_of_bits)\n",
    "\n",
    "effect_data['fp'] = [to_bin(fps[c]) if c in fps else to_bin('0') for c in effect_data['chemical'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8441, 5)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect_data = effect_data[effect_data['fp']!=to_bin('0')]\n",
    "effect_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (effect_data.groupby('species').count() > 9)['fp']\n",
    "idx = [i for i,v in zip(idx.index,idx.values) if v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>species</th>\n",
       "      <th>chemical</th>\n",
       "      <th>conc (mol/L)</th>\n",
       "      <th>fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/1</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/10025919</td>\n",
       "      <td>3.051629</td>\n",
       "      <td>0011011100010000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/1</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/10028156</td>\n",
       "      <td>5.681105</td>\n",
       "      <td>0011011100010000000000000000001100000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/1</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/100414</td>\n",
       "      <td>3.398977</td>\n",
       "      <td>0011011100011100000001110000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/1</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/100425</td>\n",
       "      <td>3.512146</td>\n",
       "      <td>0011011100011100000001110000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/1</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/10043013</td>\n",
       "      <td>3.127255</td>\n",
       "      <td>0011011100010000000000000000001111000000000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8447</th>\n",
       "      <td>8447</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/995</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/10108642</td>\n",
       "      <td>3.444898</td>\n",
       "      <td>0011011100010000000000000000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8448</th>\n",
       "      <td>8448</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/997</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/148243</td>\n",
       "      <td>0.582372</td>\n",
       "      <td>0011011100011000000001110010001000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>8449</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/997</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/50293</td>\n",
       "      <td>6.004827</td>\n",
       "      <td>0011011100011100000001110000000000000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>8450</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/997</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/52645531</td>\n",
       "      <td>6.312399</td>\n",
       "      <td>0011011100011110000001111000001100000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>8451</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/taxon/997</td>\n",
       "      <td>https://cfpub.epa.gov/ecotox/cas/62737</td>\n",
       "      <td>4.535390</td>\n",
       "      <td>0011011100011000000001100000001110000000001000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8441 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                 species  \\\n",
       "0              0    https://cfpub.epa.gov/ecotox/taxon/1   \n",
       "1              1    https://cfpub.epa.gov/ecotox/taxon/1   \n",
       "2              2    https://cfpub.epa.gov/ecotox/taxon/1   \n",
       "3              3    https://cfpub.epa.gov/ecotox/taxon/1   \n",
       "4              4    https://cfpub.epa.gov/ecotox/taxon/1   \n",
       "...          ...                                     ...   \n",
       "8447        8447  https://cfpub.epa.gov/ecotox/taxon/995   \n",
       "8448        8448  https://cfpub.epa.gov/ecotox/taxon/997   \n",
       "8449        8449  https://cfpub.epa.gov/ecotox/taxon/997   \n",
       "8450        8450  https://cfpub.epa.gov/ecotox/taxon/997   \n",
       "8451        8451  https://cfpub.epa.gov/ecotox/taxon/997   \n",
       "\n",
       "                                       chemical  conc (mol/L)  \\\n",
       "0     https://cfpub.epa.gov/ecotox/cas/10025919      3.051629   \n",
       "1     https://cfpub.epa.gov/ecotox/cas/10028156      5.681105   \n",
       "2       https://cfpub.epa.gov/ecotox/cas/100414      3.398977   \n",
       "3       https://cfpub.epa.gov/ecotox/cas/100425      3.512146   \n",
       "4     https://cfpub.epa.gov/ecotox/cas/10043013      3.127255   \n",
       "...                                         ...           ...   \n",
       "8447  https://cfpub.epa.gov/ecotox/cas/10108642      3.444898   \n",
       "8448    https://cfpub.epa.gov/ecotox/cas/148243      0.582372   \n",
       "8449     https://cfpub.epa.gov/ecotox/cas/50293      6.004827   \n",
       "8450  https://cfpub.epa.gov/ecotox/cas/52645531      6.312399   \n",
       "8451     https://cfpub.epa.gov/ecotox/cas/62737      4.535390   \n",
       "\n",
       "                                                     fp  \n",
       "0     0011011100010000000000000000000000000000000000...  \n",
       "1     0011011100010000000000000000001100000000000000...  \n",
       "2     0011011100011100000001110000000000000000000000...  \n",
       "3     0011011100011100000001110000000000000000000000...  \n",
       "4     0011011100010000000000000000001111000000000001...  \n",
       "...                                                 ...  \n",
       "8447  0011011100010000000000000000000000000000000000...  \n",
       "8448  0011011100011000000001110010001000000000000000...  \n",
       "8449  0011011100011100000001110000000000000000000000...  \n",
       "8450  0011011100011110000001111000001100000000000000...  \n",
       "8451  0011011100011000000001100000001110000000001000...  \n",
       "\n",
       "[8441 rows x 5 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#effect_data = effect_data.where(effect_data['species'].isin(idx)).dropna().reset_index()\n",
    "effect_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = effect_data[['fp','species','chemical','conc (mol/L)']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray([[fp,\n",
    "                    entity_mappings[URIRef(s)],\n",
    "                    entity_mappings[URIRef(c)],\n",
    "                    conc] for fp,s,c,conc in data if URIRef(s) in entity_mappings and URIRef(c) in entity_mappings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.trainable=False\n",
    "from tensorflow.keras.layers import Concatenate, BatchNormalization, Activation\n",
    "def mlp(input_shape,use_embedding=False):\n",
    "    \n",
    "    inp_s = Input(())\n",
    "    inp_c = Input(())\n",
    "    inp = Input(input_shape)\n",
    "    \n",
    "    if use_embedding:\n",
    "        s = embedding_model.get_layer('entity_embedding')(inp_s)\n",
    "        c = embedding_model.get_layer('entity_embedding')(inp_c)\n",
    "    else:\n",
    "        el = Embedding(len(entities),200)\n",
    "        s = el(inp_s)\n",
    "        c = el(inp_c)\n",
    "    \n",
    "    fp = Dense(128)(inp)\n",
    "    #fp = BatchNormalization()(fp)\n",
    "    fp = Activation('relu')(fp)\n",
    "    fp = Dropout(0.4)(fp)\n",
    "    \n",
    "    s = Dense(128)(s)\n",
    "    #s = BatchNormalization()(s)\n",
    "    s = Activation('relu')(s)\n",
    "    s = Dropout(0.4)(s)\n",
    "    \n",
    "    c = Dense(128)(c)\n",
    "    #c = BatchNormalization()(c)\n",
    "    c = Activation('relu')(c)\n",
    "    c = Dropout(0.4)(c)\n",
    "    \n",
    "    x = Concatenate(axis=-1)([s,c,fp])\n",
    "    x = Dense(128)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1)(x)\n",
    "    model = Model(inputs=[inp,inp_s,inp_c],outputs=x)\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    return model\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd7a81819414060b46807fe1f0c1890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Folds', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold, GroupShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "\n",
    "\n",
    "Xs,Xc = data[:,1].astype(int),data[:,2].astype(int)\n",
    "y = data[:,3].astype('float32')\n",
    "X = data[:,0]\n",
    "\n",
    "X = np.asarray(list(map(lambda x: np.asarray([float(a) for a in x]), X))).astype('float32')\n",
    "\n",
    "scores = []\n",
    "\n",
    "groups = Xc\n",
    "\n",
    "for seed in tq.tqdm(range(10)):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    oof = np.zeros(y.shape)\n",
    "    oof_embedding = np.zeros(y.shape)\n",
    "\n",
    "    for i,(train,test) in tq.tqdm(enumerate(GroupKFold(5).split(X,y,groups=groups))\n",
    "                                  ,total=5,desc='Folds',leave=False):\n",
    "\n",
    "        model = mlp(X.shape[-1],use_embedding=False)\n",
    "        model.fit((X[train],Xs[train],Xc[train]),y[train],\n",
    "                  validation_data=((X[test],Xs[test],Xc[test]),y[test]),\n",
    "                  batch_size=8192,epochs=1000,verbose=0,\n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n",
    "\n",
    "        oof[test] += model.predict((X[test],Xs[test],Xc[test])).ravel()\n",
    "\n",
    "        model = mlp(X.shape[-1],use_embedding=True)\n",
    "        model.fit((X[train],Xs[train],Xc[train]),y[train],\n",
    "                  validation_data=((X[test],Xs[test],Xc[test]),y[test]),\n",
    "                  batch_size=8192,epochs=1000,verbose=0,\n",
    "                 callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n",
    "\n",
    "        oof_embedding[test] += model.predict((X[test],Xs[test],Xc[test])).ravel()    \n",
    "    \n",
    "    scores.append((r2_score(y,oof),r2_score(y,oof_embedding)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Out-of-fold, 0.11799794378627744 +- 0.016752933877773695',\n",
       " 'Out-of-fold embedding, 0.18855524973345555 +- 0.013843017892894377')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.asarray(scores)\n",
    "m,s = np.mean(scores,axis=0),np.std(scores,axis=0)\n",
    "f'Out-of-fold, {m[0]} +- {s[0]}', f'Out-of-fold embedding, {m[1]} +- {s[1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove species or chemical groups. \n",
    "# Rare species. Get chemical groups, species groups. Fish -> amphibes. Insects -> crustsaens\n",
    "# Per chemical, how many species. \n",
    "# What is 100% coverage. MxN matrix without holes.\n",
    "# Endangered species https://cfpub.epa.gov/ecotox/group/U.S.ThreatenedandEndangeredSpecies\n",
    "# Weekly update meeting, not fridays. \n",
    "# TODO write in Teams channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1750, 604)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(effect_data['species'].unique()),len(effect_data['chemical'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
